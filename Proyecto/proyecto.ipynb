{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2fc4a04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5eb86017",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Líneas a incluir en el documento .tex para eliminar la primera hoja (innecesaria porque el título en formato aparece en la segunda)\n",
    "#\\usepackage{atbegshi}\n",
    "#\\AtBeginDocument{\\AtBeginShipoutNext{\\AtBeginShipoutDiscard}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3b703a",
   "metadata": {},
   "source": [
    "\\let\\firstpage\\relax\n",
    "\n",
    "\\makeatletter\n",
    "\\begin{center}\n",
    "\n",
    "\\begin{titlepage}\n",
    "\n",
    "{\\includegraphics[width=0.2\\textwidth]{usblogo.png}\\par} \n",
    "\t{\\bfseries\\scshape\\LARGE Universidad Simón Bolívar \\par}\n",
    "\t{\\scshape\\large Dpto. de Tecnología y Electrónica \\par}\n",
    "\t{\\scshape\\large EC7817 - Tópico especial II - Inteligencia Artificial en Biomédica \\par}\n",
    "    \\vspace{0.2cm}\n",
    "\n",
    "{\\bfseries\\scshape\\LARGE \\@title \\par}\n",
    "\n",
    "\\vspace{0.2cm}\n",
    "Autor: \\@author\n",
    "\n",
    "Profesor: Miguel Altuve\n",
    "\n",
    "\\vspace{0.2cm}\n",
    "\n",
    "\\@date\n",
    "\n",
    "\\let\\newpage\\relax\t\n",
    "\n",
    "\\end{titlepage}\n",
    "\n",
    "\\end{center}\n",
    "\n",
    "\\makeatother\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27005824",
   "metadata": {},
   "source": [
    "El consumo energético de cada individuo varías de acuerdo a la salud, genética y actividad que éste realiza. El reducir el consumo energético de requerido para una actividad permite prolongar el tiempo de realización de la misma. Esto puede ser de mucha utilidad en el campo de la medicina, deportiva y hasta en el campo laboral. \n",
    "\n",
    "Diversos estudios demuestran que las personas con discapacidad motriz suelen requerir más energía para realizar actividades de menor capacidad, lo que limita aún más su movilidad [1]. Diversos dispositivos robóticos (prótesis motorizadas, exoesqueletos, ente otros) se han desarrollado para reducir el costo energético de una persona al realizar actividades, tanto para paciente con carencia de movilidad como para personas sanas que debe desempeñar tareas de alta demanda energética. Estos dispositivos se componen por sensores, sistemas de control y actuadores, que deben ajustarse al paciente [1].\n",
    "\n",
    "Si bien, en muchos casos, sobre todo en el área clínica, la estimación del consumo energético la realiza manualmente el doctor de acuerdo a sus observaciones y la retroalimentación verbal del paciente; existen algoritmos de estimación de consumo energético de un paciente. Uno es el algoritmo “body-in-the-loop”, que consiste en un proceso de optimización de ajuste iterativo y automático de los parámetros de los dispositivos robóticos de asistencia para minimizar una función de costo fisiológico mientras una persona usa el dispositivo. La evaluación automática del costo energético es actualmente uno de los factores que limitan la velocidad en la traducción de estos algoritmos a dispositivos de asistencia del mundo real [1].\n",
    "\n",
    "La estimación de consumo energético actualmente se realiza mediante la calorimetría, que se basa en la medición de consumo de oxígeno y producción de dióxido de carbono de paciente. Si bien, permite obtener un resultado, su uso prolongado no es viable debido a al equipo de medición, que consiste en una máscara que debe ir colocada en la boca en todo momento, la cual se conecta a un equipo de procesamiento [1].\n",
    "\n",
    "En vista de lo impráctico del método más usado de medición de consumo energético, nace la necesidad de buscar alternativas para obtener una medición precisa del metabolismo de cada paciente a partir de señales biológicas de diferente naturaleza, que pudieran ser de fácil medición con equipos compactos que no sea incómodos. En este proyecto, se pretende presentar una primera aproximación de una posible solución mediante modelos de Machine Learning que pudieran usar señales diferentes de usuarios y que demuestren ser capaces de adaptarse a cada individuo con suficiente precisión como para ser considerado apropiado para su uso.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d445888a",
   "metadata": {},
   "source": [
    "\\vspace{1cm} \\section*{\\scshape\\Large Objetivo General}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e3f7cb",
   "metadata": {},
   "source": [
    "\\begin{itemize}\n",
    "    \\item[$\\bullet$] Presentar diferentes modelos de Machine Learning capaces de adaptarse al problema a estudiar con suficiente precisión (mayor al 95%).\n",
    "\\end{itemize}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960fd614",
   "metadata": {},
   "source": [
    "\\newpage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b413b4c7",
   "metadata": {},
   "source": [
    "\\vspace{1cm} \\section*{\\scshape\\Large Código}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1c6cfd",
   "metadata": {},
   "source": [
    "\\vspace{1cm} \\subsection*{\\scshape\\Large Instanciación de bibliotecas}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "787230e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Se instancian las bibliotecas a implementar\n",
    "\n",
    "import numpy as np\n",
    "#import csv\n",
    "#import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cbook as cbook\n",
    "#import statistics as stats\n",
    "\n",
    "import scipy\n",
    "from scipy import stats\n",
    "import scipy.cluster as scpcl\n",
    "import scipy.cluster.hierarchy as scpch\n",
    "import scipy.io as scpio\n",
    "import scipy.signal as scpsg\n",
    "import scipy.ndimage as scpni\n",
    "import scipy.interpolate as scpnt\n",
    "#from scipy.cluster.hierarchy import dendrogram\n",
    "#from scipy.stats import boxcox\n",
    "#from scipy.special import inv_boxcox\n",
    "\n",
    "import sklearn\n",
    "import sklearn.model_selection as sklms\n",
    "import sklearn.linear_model as skllm\n",
    "import sklearn.metrics as sklmt\n",
    "import sklearn.neural_network as sklnn\n",
    "import sklearn.cluster as sklcl\n",
    "#from sklearn import cross_validation\n",
    "#import sklearn.cross_validation as sklcv \n",
    "#from sklearn.neural_network import MLPClassifier\n",
    "#from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# presentate data in table format\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "\n",
    "# to load .mat data file\n",
    "import mat73\n",
    "import h5py\n",
    "\n",
    "\n",
    "# modelo de RNN\n",
    "import torch\n",
    "import torch.nn as trnn\n",
    "import torch.optim as trOptim\n",
    "import torch.nn.functional as trFnl\n",
    "\n",
    "\n",
    "\n",
    "#format of print for numpy float\n",
    "np.set_printoptions(precision = 5, formatter = {'float_kind': lambda x: \"{0:0.5f}\".format(x)}, threshold = 40, edgeitems = 20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "557ea28a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       ".output_png {\n",
       "    display: table-cell;\n",
       "    text-align: center;\n",
       "    vertical-align: middle;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Configuration to display center plots\n",
    "\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "HTML(\"\"\"\n",
    "<style>\n",
    ".output_png {\n",
    "    display: table-cell;\n",
    "    text-align: center;\n",
    "    vertical-align: middle;\n",
    "}\n",
    "</style>\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673d318c",
   "metadata": {},
   "source": [
    "\\vspace{1cm} \\subsection*{\\scshape\\large Variables Globales implementadas a lo largo del código}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9798d9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# names\n",
    "subjname = np.char.add(np.array(['Subject']*10).astype(np.str_), np.char.add( np.floor_divide(np.arange(10)+1, 10).astype(np.str_), np.remainder(np.arange(10)+1, 10).astype(np.str_)) )\n",
    "filename = np.char.add( subjname, np.array(['.mat']*10).astype(np.str_) )\n",
    "actvname = np.array(['Backwards', 'Cycling', 'Incline', 'Running', 'Walking']).astype(np.str_)\n",
    "measname = np.array(['APDM_Accel', 'EMG', 'Empatica_Accel', 'Empatica_Physio', 'Metabolics_System']).astype(np.str_)\n",
    "varsname = np.array(['Data', 'Labels', 'SamplingRate']).astype(np.str_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25cbce6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def callData( data, i, j, k, l ):\n",
    "    \n",
    "    return data[i][ subjname[i] ][ actvname[j] ][ measname[k] ][ varsname[l] ][:,:]\n",
    "\n",
    "#endfunction\n",
    "\n",
    "\n",
    "def callData1( data, i, j, k ):\n",
    "    \n",
    "    return data[i][ subjname[i] ][ actvname[j] ][ measname[k] ]\n",
    "\n",
    "#endfunction\n",
    "\n",
    "\n",
    "def callData2( data, i, j ):\n",
    "    \n",
    "    return data[i][ subjname[i] ][ actvname[j] ]\n",
    "\n",
    "#endfunction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4adee2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filtros\n",
    "def filtros(data, isubj, iactv, imeas):\n",
    "    IirHP30 = scpsg.iirdesign( wp=31, ws=29, gpass=1, gstop=80, analog=False, ftype='ellip', fs=callData( data, isubj, iactv, imeas, 2 )[0][0] )\n",
    "    IirLP350 = scpsg.iirdesign( wp=349, ws=351, gpass=1, gstop=80, analog=False, ftype='ellip', fs=callData( data, isubj, iactv, imeas, 2 )[0][0] )\n",
    "\n",
    "    return IirHP30, IirLP350\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1f67db9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metodologías de la regresión lineal\n",
    "methodName = ['5k entrenamiento','5k evaluación','5k toda la data','10k entrenamiento','10k evaluación','10k toda la data']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71e2689",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cda6f4d7",
   "metadata": {},
   "source": [
    "\\vspace{1cm} \\subsection*{\\scshape\\large Funciones implementadas a lo largo del código}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eafefe10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eee72698",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cálculo de los Parámetros estadísticos de interés\n",
    "\n",
    "def StatsVars( data, title ):\n",
    "    \n",
    "\n",
    "    # Inicialización\n",
    "\n",
    "    data_Mean = np.zeros((np.size(data,1),1))       #media\n",
    "    data_Median = np.zeros((np.size(data,1),1))     #mediana\n",
    "    data_Mode = np.zeros((np.size(data,1),1))       #moda\n",
    "    data_Max = np.zeros((np.size(data,1),1))        #máximo\n",
    "    data_Min = np.zeros((np.size(data,1),1))        #mínimo\n",
    "    data_Range = np.zeros((np.size(data,1),1))      #rango\n",
    "    data_Desv = np.zeros((np.size(data,1),1))       #desviación\n",
    "    #data_Skew = np.zeros((np.size(data,1),1))       #asimetría\n",
    "    #data_Kurt = np.zeros((np.size(data,1),1))       #curtosis\n",
    "    \n",
    "\n",
    "    # cálculo de los parámetros estadísticos\n",
    "\n",
    "    data_Mean = np.mean(data, axis = 0)\n",
    "    data_Median = np.median(data, axis = 0)\n",
    "    data_Mode = stats.mode(data, axis = 0)\n",
    "    data_Max = np.max(data, axis = 0)\n",
    "    data_Min = np.min(data, axis = 0)\n",
    "    data_Range = data_Max - data_Min\n",
    "    data_Desv = np.std(data, axis = 0)\n",
    "    #data_Skew = stats.skew(data, axis = 0, bias = 0)\n",
    "    #data_Kurt = stats.kurtosis(data, axis = 0, bias = 0)\n",
    "    \n",
    "    # Se inserta el formato de presentación de los datos\n",
    "    np.set_printoptions(formatter={'float': lambda x: \"{:.5e}\".format(x)}, suppress= True)\n",
    "    \n",
    "    # Presentación de los valores de los parámetros estadísticos estudiados\n",
    "\n",
    "    print('la media de los atributos para la ' + title + ' es:');\n",
    "    print(data_Mean);\n",
    "    print();\n",
    "    print('la mediana de los atributos para la ' + title + ' es:');\n",
    "    print(data_Median);\n",
    "    print();\n",
    "    print('la moda de los atributos para la ' + title + ' es:');\n",
    "    print(data_Mode);\n",
    "    print();\n",
    "    print('el valor máximo de los atributos para la ' + title + ' es:');\n",
    "    print(data_Max);\n",
    "    print();\n",
    "    print('el valor mínimo de los atributos para la ' + title + ' es:');\n",
    "    print(data_Min);\n",
    "    print();\n",
    "    print('lel rango de los atributos para la ' + title + ' es:');\n",
    "    print(data_Range);\n",
    "    print();\n",
    "    print('la desviación estándar de los atributos para la ' + title + ' es:');\n",
    "    print(data_Desv);\n",
    "    print();\n",
    "    #print('la asimetría de los atributos para la ' + title + ' es:');\n",
    "    #print(data_Skew);\n",
    "    #print();\n",
    "    #print('el curtosis de los atributos para la ' + title + ' es:');\n",
    "    #print(data_Kurt);\n",
    "    #print();\n",
    "\n",
    "    \n",
    "    # retorna las variables estadísticas de interés\n",
    "    \n",
    "    return data_Mean, data_Median, data_Mode, data_Max, data_Min, data_Range, data_Desv, data_Skew, data_Kurt;\n",
    "\n",
    "#endfunction\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b62f6a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# funciones de procesamiento\n",
    "\n",
    "def APDLprocessing( data, SampRate ):\n",
    "    \n",
    "    aux = np.copy( data )\n",
    "    aux[2:,:] = scpsg.savgol_filter( data[2:,:], window_length= int(SampRate/0.1) +1, polyorder=3, deriv=0, delta=1.0, axis=1, mode='interp')\n",
    "    return aux\n",
    "    \n",
    "#endfunction\n",
    "\n",
    "\n",
    "def ECGprocessing( data, SampRate ):\n",
    "    \n",
    "    aux = np.copy( data )\n",
    "    aux[2:,:] = scpsg.filtfilt( IirHP30[0][:], IirHP30[0][:], data[2:,:], axis=1 )\n",
    "    aux[2:,:] = scpsg.filtfilt( IirLP350[0][:], IirLP350[0][:], aux[2:,:], axis=1 )\n",
    "    aux[2:,:] = scpsg.savgol_filter( aux[2:,:], window_length= int(SampRate) +1, polyorder=3, deriv=0, delta=1.0, axis=1, mode='interp')\n",
    "    return aux\n",
    "    \n",
    "#endfunction\n",
    "\n",
    "def EpAcProcessing( data, SampRate ):\n",
    "    \n",
    "    aux = np.copy( data )\n",
    "    aux[2:,:] = scpsg.savgol_filter( data[2:,:], window_length= int(SampRate/0.1) +1, polyorder=3, deriv=0, delta=1.0, axis=1, mode='interp')\n",
    "    return aux\n",
    "\n",
    "#endfunction\n",
    "\n",
    "\n",
    "def PhysProcessing( data, SampRate ):\n",
    "\n",
    "    aux = np.copy( data )\n",
    "    aux[2:,:] = scpsg.savgol_filter( data[2:,:], window_length= int(SampRate/0.1) +1, polyorder=3, deriv=0, delta=1.0, axis=1, mode='interp')\n",
    "    return aux\n",
    "    \n",
    "#endfunction\n",
    "    \n",
    "def MetaProcessing( data, SampRate ):\n",
    "    \n",
    "    aux = np.copy( data )\n",
    "    aux[2:np.size( aux[:,:], 0) -2,:] = scpsg.savgol_filter( data[2:np.size( data[:,:], 0)-2 ,:], window_length= int(SampRate) +1, polyorder=3, deriv=0, delta=1.0, axis=1, mode='interp')\n",
    "    aux[-1,:] = scpsg.savgol_filter( aux[-1,:], window_length= int(SampRate) +1, polyorder=3, deriv=0, delta=1.0, axis=0, mode='interp')\n",
    "    return aux\n",
    "    \n",
    "#endfunction\n",
    "\n",
    "\n",
    "def filtradoSeñal( data, SampRate, i ):\n",
    "    \n",
    "    # Se eliminan los vectores nan\n",
    "    data = np.delete( data, np.where( np.isnan(data) )[0], axis=0 )\n",
    "    \n",
    "    \n",
    "    # Se filtra la señal de acuerdo al tipo de señal\n",
    "    if i == 0:\n",
    "        return APDLprocessing( data, SampRate )\n",
    "    elif i == 1:\n",
    "        return ECGprocessing( data, SampRate )\n",
    "    elif i == 2:\n",
    "        return EpAcProcessing( data, SampRate )\n",
    "    elif i == 3:\n",
    "        return PhysProcessing( data, SampRate )\n",
    "    elif i == 4:\n",
    "        return MetaProcessing( data, SampRate )\n",
    "    \n",
    "    '''\n",
    "    # Se filtra la señal de acuerdo al tipo de señal\n",
    "    filtProc = {\n",
    "        0: APDLprocessing( data, SampRate ),\n",
    "        1: ECGprocessing( data, SampRate ),\n",
    "        2: EpAcProcessing( data, SampRate ),\n",
    "        3: PhysProcessing( data, SampRate ),\n",
    "        4: MetaProcessing( data, SampRate ),\n",
    "    }\n",
    "    return filtProc.get(i, None )\n",
    "    '''\n",
    "    \n",
    "#endfunction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "136e8525",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def proc1ActData( data, procDName, isubj, iactv ):\n",
    "\n",
    "    for i in range( np.size(measname,0) ):\n",
    "        #callData1( data, 0, 0, i ).create_group(\"dataprcs\")\n",
    "        #del callData1( data, 0, 0, i )[\"dataprcs1\"]\n",
    "        callData1( data, isubj, iactv, i )[procDName] = filtradoSeñal( callData(data, isubj, iactv, i, 0 )[:,:], callData(data, isubj, iactv, i, 2 )[0][0], i )\n",
    "        \n",
    "    #endfor\n",
    "\n",
    "#endfunction\n",
    "\n",
    "\n",
    "def procAllActData( data, procDName, isubj ):\n",
    "\n",
    "    for i in range( np.size(actvname,0) ):\n",
    "        \n",
    "        proc1ActData( data, procDName, isubj, i )\n",
    "        \n",
    "    #endfor\n",
    "\n",
    "#endfunction\n",
    "\n",
    "\n",
    "def procAllSubActvData( data, procDName ):\n",
    "    \n",
    "    for i in range( np.size(subjname,0) ):\n",
    "        \n",
    "        for j in range( np.size(actvname,0) ):\n",
    "            \n",
    "            proc1ActData( data, procDName, i, j )\n",
    "\n",
    "        #endfor\n",
    "    \n",
    "    #endfor\n",
    "    \n",
    "#endfunction\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8557c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# interpolación para remuestreo de las señales\n",
    "def signResamp( data, fr, tmax ):\n",
    "    \n",
    "    tnew = np.arange( 0, tmax, 1/fr )\n",
    "\n",
    "    interpFunc = scpnt.interp1d( data[0,:], data[1:,:], kind='linear', axis=1, copy=True, bounds_error=None, fill_value=\"extrapolate\" )\n",
    "    Daux = np.zeros( ( np.size( data[:,:],0 ), np.size( tnew,0 ) ) )\n",
    "    \n",
    "    Daux[0,:] = tnew\n",
    "    Daux[1:,:] = interpFunc(tnew)\n",
    "    \n",
    "    return Daux\n",
    "\n",
    "#endfunction\n",
    "\n",
    "\n",
    "# tiempo final del remuestreo\n",
    "def tmaxSamp( data ):\n",
    "    \n",
    "    iteraux = np.zeros( (np.size(measname,0)) )\n",
    "    \n",
    "    for i in range( np.size(measname,0) ):\n",
    "        iteraux = np.max( data[ measname[i] ]['Data'][0,:] )\n",
    "        \n",
    "    #endfor\n",
    "    \n",
    "    return np.min( iteraux )\n",
    "    \n",
    "    \n",
    "#endfuntion\n",
    "\n",
    "\n",
    "# tiempo inicial del remuestreo\n",
    "def tminSamp( data ):\n",
    "    \n",
    "    iteraux = np.zeros( (np.size(measname,0)) )\n",
    "    \n",
    "    for i in range( np.size(measname,0) ):\n",
    "        iteraux = np.min( data[ measname[i] ]['Data'][0,:] )\n",
    "        \n",
    "    #endfor\n",
    "    \n",
    "    return np.max( iteraux )\n",
    "    \n",
    "    \n",
    "#endfuntion\n",
    "\n",
    "\n",
    "# data (toda) de una actividad remeustrada\n",
    "def ActvReSampData( data, name, isubj, iactv ):\n",
    "    \n",
    "    tmax = tmaxSamp( callData2( data, isubj, iactv) )\n",
    "    tmin = tminSamp( callData2( data, isubj, iactv) )\n",
    "    \n",
    "    dpaux0 = signResamp( callData1(data, isubj, iactv, 0)[name][:,:], 500, tmax )\n",
    "    dpaux1 = signResamp( callData1(data, isubj, iactv, 1)[name][:,:], 500, tmax )\n",
    "    dpaux2 = signResamp( callData1(data, isubj, iactv, 2)[name][:,:], 500, tmax )\n",
    "    dpaux3 = signResamp( callData1(data, isubj, iactv, 3)[name][:,:], 500, tmax )\n",
    "    dpaux4 = signResamp( callData1(data, isubj, iactv, 4)[name][:,:], 500, tmax )\n",
    "    \n",
    "    # promedio del consumo energético de los modelos Garby and Astrup 1987 y Péronnet and Massicotte 1991\n",
    "    EnerExp = ( (16.89 *dpaux4[2,:] + 4.84 *dpaux4[3,:])/1000 + (16.04 *dpaux4[2,:] + 4.94 *dpaux4[3,:])/1000 ) /2\n",
    "    \n",
    "    callData2( data, isubj, iactv )[name] = np.concatenate( ( [dpaux0[0,:]], [EnerExp], dpaux0[2:,:], dpaux1[2:,:], dpaux2[2:,:], dpaux3[2:,:], dpaux4[2:,:] ), axis=0 )\n",
    "    \n",
    "    del dpaux0, dpaux1, dpaux2, dpaux3, dpaux4\n",
    "    #return EnerExp\n",
    "    \n",
    "#endfunction\n",
    "\n",
    "\n",
    "def AllActvReSampData( data, name, isubj ):\n",
    "    \n",
    "    for i in range( np.size(actvname,0) ):\n",
    "        \n",
    "        ActvReSampData( data, name, isubj, i )\n",
    "    \n",
    "    #endfor\n",
    "    \n",
    "#endfunction\n",
    "\n",
    "\n",
    "def AllSunjActvReSampData( data, name ):\n",
    "    \n",
    "    for i in range( np.size(subjname,0) ):\n",
    "        #print( 'i = ', i)\n",
    "        \n",
    "        for j in range( np.size(actvname,0) ):\n",
    "            #print('j = ', j)\n",
    "            \n",
    "            ActvReSampData( data, name, i, j )\n",
    "        \n",
    "        #endfor\n",
    "    \n",
    "    #endfor\n",
    "    \n",
    "#endfunction\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "80be54c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def delAllMeasData( data, procDName, isubj, iactv ):\n",
    "\n",
    "    for i in range( np.size(measname,0) ):\n",
    "        #callData1( data, 0, 0, i ).create_group(\"dataprcs\")\n",
    "        del callData1( data, isubj, iactv, i )[procDName]\n",
    "        #callData1( data, isubj, iactv, i )[procDName] = filtradoSeñal( callData(data, isubj, iactv, i, 0 )[:,:], callData(data, isubj, iactv, i, 2 )[0][0], i )\n",
    "        \n",
    "    #endfor\n",
    "\n",
    "#endfunction\n",
    "\n",
    "\n",
    "def delAllActvMeasData( data, procDName, isubj ):\n",
    "\n",
    "    for i in range( np.size(actvname,0) ):\n",
    "        \n",
    "        del1ActData( data, procDName, isubj, i )\n",
    "        \n",
    "    #endfor\n",
    "\n",
    "#endfunction\n",
    "\n",
    "\n",
    "def delAllSubActvMeasData( data, procDName ):\n",
    "    \n",
    "    for i in range( np.size(subjname,0) ):\n",
    "        \n",
    "        for j in range( np.size(actvname,0) ):\n",
    "            \n",
    "            del1ActData( data, procDName, i, j )\n",
    "\n",
    "        #endfor\n",
    "    \n",
    "    #endfor\n",
    "    \n",
    "#endfunction\n",
    "\n",
    "\n",
    "def delAct1Data( data, procDName, isubj, iactv ):\n",
    "    \n",
    "    #callData2( data, 0, 0 ).create_group(\"dataprcs\")\n",
    "    del callData2( data, isubj, iactv )[procDName]\n",
    "    #callData2( data, isubj, iactv )[procDName] = filtradoSeñal( callData(data, isubj, iactv, i, 0 )[:,:], callData(data, isubj, iactv, i, 2 )[0][0], i )\n",
    "        \n",
    "    #endfor\n",
    "\n",
    "#endfunction\n",
    "\n",
    "\n",
    "def delAllActvMeasData( data, procDName, isubj ):\n",
    "\n",
    "    for i in range( np.size(actvname,0) ):\n",
    "        \n",
    "        #callData2( data, i, 0 ).create_group(\"dataprcs\")\n",
    "        del callData2( data, isubj, i )[procDName]\n",
    "        #callData2( data, i, iactv )[procDName] = filtradoSeñal( callData(data, isubj, iactv, i, 0 )[:,:], callData(data, isubj, iactv, i, 2 )[0][0], i )\n",
    "        \n",
    "    #endfor\n",
    "\n",
    "#endfunction\n",
    "\n",
    "\n",
    "def delAllSubjAllAct1Data( data, procDName ):\n",
    "    \n",
    "    for i in range( np.size(subjname,0) ):\n",
    "        \n",
    "        for j in range( np.size(actvname,0) ):\n",
    "            \n",
    "            #callData2( data, i, 0 ).create_group(\"dataprcs\")\n",
    "            del callData2( data, i, j )[procDName]\n",
    "            #callData2( data, i, iactv )[procDName] = filtradoSeñal( callData(data, isubj, iactv, i, 0 )[:,:], callData(data, isubj, iactv, i, 2 )[0][0], i )\n",
    "        \n",
    "        #endfor\n",
    "        \n",
    "    #endfor\n",
    "\n",
    "#endfunction\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf9a173",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f769f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def signalplot( xdata, ydata, title, figsize=(10,4) ):\n",
    "    \n",
    "    figure = plt.fig( figsize = figsize )\n",
    "    \n",
    "    plt.plot( xdata, ydata )\n",
    "    plt.xlabel('time [s]')\n",
    "    plt.ylabel('signal')\n",
    "    plt.title(title)\n",
    "\n",
    "#endfunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "041e99ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# función para calcular el Residual Sum of Squares (RSS)\n",
    "\n",
    "def RSS(y_real, y_calc):\n",
    "    return np.sum ( ( y_real - y_calc ) * ( y_real - y_calc ) )\n",
    "\n",
    "#endfunction\n",
    "\n",
    "\n",
    "# R^2 del entrenamiento\n",
    "\n",
    "def R2entPrint( R2ent, dataTitle ):\n",
    "    \n",
    "    if np.sum(R2ent) is not None:\n",
    "        print(dataTitle + ': R^2 de cada iteración con los de entrenamiento:')\n",
    "        print(R2ent)\n",
    "        print('\\n')\n",
    "\n",
    "#endfunction\n",
    "\n",
    "\n",
    "# RSS del entrenamiento\n",
    "\n",
    "def RSSentPrint( RSSent, dataTitle ):\n",
    "    \n",
    "    if np.sum(RSSent) is not None:\n",
    "        print(dataTitle + ': RSS de cada iteración con los datos de entrenamiento:')\n",
    "        print(RSSent)\n",
    "        print('\\n')\n",
    "\n",
    "#endfunction\n",
    "\n",
    "\n",
    "# R^2 de la evaluación\n",
    "\n",
    "def R2evaPrint( R2eva, dataTitle ):\n",
    "    \n",
    "    if np.sum(R2eva) is not None:\n",
    "        print(dataTitle + ': R^2 de cada iteración con los datos de prueba:')\n",
    "        print(R2eva)\n",
    "        print('\\n')\n",
    "\n",
    "#endfunction\n",
    "\n",
    "\n",
    "# R^2 de la evaluación\n",
    "\n",
    "def RSSevaPrint( RSSeva, dataTitle ):\n",
    "    \n",
    "    if np.sum(RSSeva) is not None:\n",
    "        print(dataTitle + ': RSS de cada iteración con los datos de prueba:')\n",
    "        print(RSSeva)\n",
    "        print('\\n')\n",
    "\n",
    "#endfunction\n",
    "\n",
    "\n",
    "# R^2 usando la función cross_val_score\n",
    "\n",
    "def R2evaCVSPrint( R2CValScore, dataTitle ):\n",
    "    \n",
    "    if np.sum(R2CValScore) is not None:\n",
    "        print('error del modelo usando el comando cross_val_score:')\n",
    "        print(R2CValScore)\n",
    "        print('\\n')\n",
    "\n",
    "#endfunction\n",
    "\n",
    "\n",
    "# presentar todos los errores resultados del modelo\n",
    "\n",
    "def modelErrorPrint( dataTitle=None , RSSent=None , RSSeva=None , R2ent=None , R2eva=None , R2CValScore=None ):\n",
    "    \n",
    "    # formato de los errores\n",
    "    np.set_printoptions(formatter={'float': lambda x: \"{0:0.5f}\".format(x)}, suppress = True)\n",
    "    \n",
    "    # errores de interés obtenidos\n",
    "    RSSentPrint( RSSent, dataTitle )\n",
    "    \n",
    "    RSSevaPrint( RSSeva, dataTitle )\n",
    "    \n",
    "    R2entPrint( R2ent, dataTitle )\n",
    "    \n",
    "    R2evaPrint( R2eva, dataTitle )\n",
    "    \n",
    "    R2evaCVSPrint( R2CValScore, dataTitle )\n",
    "\n",
    "#endfunction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f8b9a7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Linear Regression & data-split\n",
    "\n",
    "def LinearRegrDSplit( data, trdSplit, varShuffle = False, randomState = None, stratifyData = None ):\n",
    "    \n",
    "    # Se instancian los data set de entrenamiento y evaluación\n",
    "    Xtrain, Xtest, Ytrain, Ytest = sklms.train_test_split( data[:,1:], data[:,0], stratify = stratifyData, random_state = randomState, train_size = trdSplit )\n",
    "    \n",
    "    # Se instancia el modelo\n",
    "    model = skllm.LinearRegression()\n",
    "    \n",
    "    # Variables de interés a almacenar\n",
    "    #RSSent = np.zeros((1))\n",
    "    #RSSeva = np.zeros((1))\n",
    "    #R2ent = np.zeros((1))\n",
    "    #R2eva = np.zeros((1))\n",
    "    \n",
    "    # Se entrena el modelo\n",
    "    model.fit( Xtrain, Ytrain )\n",
    "    \n",
    "    # Se prueba el modelo (datos de entrenamiento: resultados del modelo)\n",
    "    modelOutTrain = model.predict(Xtrain)\n",
    "\n",
    "    # Evaluación de la predicción (datos de entrenamiento)\n",
    "    RSSent = RSS( Ytrain , modelOutTrain )\n",
    "    R2ent = model.score(Xtrain, Ytrain)     # Root Mean Square\n",
    "\n",
    "    # Se prueba el modelo (datos de prueba: resultados del modelo entrenado)\n",
    "    modelOutEval = model.predict(Xtest)\n",
    "\n",
    "    # Evaluación de la predicción (datos de prueba)\n",
    "    RSSeva = RSS( Ytest , modelOutEval )\n",
    "    R2eva = model.score( Xtest, Ytest )     # Root Mean Square\n",
    "    \n",
    "    return RSSent , RSSeva , R2ent , R2eva , model\n",
    "    \n",
    "#endfunction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5ba29bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot1Signal( xdata, ydata, title, xlabel='Time [s]', ylabel='signal', figsize=(15,5), color='b' ):\n",
    "    \n",
    "    fig = plt.figure(figsize = figsize)\n",
    "    \n",
    "    plt.plot( xdata, ydata, c=color )\n",
    "    \n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    #plot\n",
    "    plt.show()\n",
    "    \n",
    "#endfunction\n",
    "\n",
    "\n",
    "def plotAllSignal( data, title, xlabel=None, ylabel=None, figsize=(15,5), color='b' ):\n",
    "    \n",
    "    \n",
    "    if xlabel == None:\n",
    "        xlabel = ['Time [s]']*np.size(data,0)\n",
    "        \n",
    "    if ylabel == None:\n",
    "        ylabel = ['signal']*np.size(data,0)\n",
    "    \n",
    "    \n",
    "    for i in range( np.size(data,0)-2 ):\n",
    "        \n",
    "        if  np.size( np.where( np.isnan(data[i+2,:]) ) ) == 0:\n",
    "            \n",
    "            plot1Signal( xdata=data[0,:], ydata=data[i+2,:], title=title[i], xlabel=xlabel[i], ylabel=ylabel[i], figsize=figsize, color=color )\n",
    "        \n",
    "        #endif\n",
    "        \n",
    "    #endfor\n",
    "    \n",
    "#endfuntion\n",
    "\n",
    "\n",
    "def plotAllMeasSingal( data, measname, title='', figsize=(15,5) ):\n",
    "    \n",
    "    color= ['r','g','b','m','c','y']\n",
    "    \n",
    "    for i in range( np.size(measname) ):\n",
    "        \n",
    "        ftitle = np.char.add( np.array([ title + measname[i] +  ' - signal ']*( np.size( data[ measname[i] ][ 'Data' ],0 ) -2 )).astype(np.str_), (np.arange( np.size( data[ measname[i] ][ 'Data' ],0 ) -2) +1).astype(np.str_))\n",
    "        \n",
    "        plotAllSignal( data[ measname[i] ][ 'Data' ][:,:], ftitle, figsize=figsize, color=color[i] )\n",
    "        \n",
    "    #endfor\n",
    "    \n",
    "#endfunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "d3aab8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "allResults = np.array( [ mR2ent5K, mR2eva5K, mR2all5K, mR2ent10K, mR2eva10K, mR2all10K ] )\n",
    "\n",
    "def LRallTables( allResults ):\n",
    "    \n",
    "    table = np.empty( np.size(allResults,0), dtype=object )\n",
    "\n",
    "    for j in range( np.size(allResults,0) ):\n",
    "\n",
    "        table[j] = PrettyTable()\n",
    "        table[j].field_names = np.concatenate(([ \"subjects\"], actvname, [\"mean\"] + [\"SD\"]), axis=0)\n",
    "\n",
    "        for i in range( np.size(subjname,0) ):\n",
    "\n",
    "            table[j].add_row(  np.concatenate( ([subjname[i]], np.round(allResults[j,i,:],3), np.round([np.mean(allResults[j,i,:])],3), np.round([np.std(allResults[j,i,:])],3) ), axis=0) )\n",
    "\n",
    "        #endfor\n",
    "        \n",
    "        table[j].add_row( np.concatenate( (['media'], [np.round(np.mean(allResults[j,:,k]),3) for k in range( np.size(allResults,2) )], [\"--\"], [\"--\"] ), axis=0) )\n",
    "        table[j].add_row( np.concatenate( (['STD'], [np.round(np.std(allResults[j,:,k]),3) for k in range( np.size(allResults,2) )], [\"--\"], [\"--\"] ), axis=0) )\n",
    "        \n",
    "    #endfor\n",
    "    \n",
    "    return table\n",
    "\n",
    "#end fuction\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "b686ddc2",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "# presentación de los resultados en tabla\n",
    "def printResults( ResultTables, title, methodName ):\n",
    "    \n",
    "    \n",
    "    for i in range( np.size(allResults,0) ):\n",
    "        \n",
    "        print(title + methodName[i])\n",
    "        print(ResultTables[i])\n",
    "        print()\n",
    "        \n",
    "    #endfor\n",
    "    \n",
    "#endfunction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7bbd14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3974697c",
   "metadata": {},
   "source": [
    "\\vspace{1cm} \\subsection*{\\scshape\\large Clases creadas}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e0c66e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d322a6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Clase que almacena los datos de interés del modelo\n",
    "class ModelsInfo:\n",
    "    \n",
    "    def __init__(self, model_=None, RSSent_=None, RSSeva_=None, R2ent_=None, R2eva_=None, Betas_=None, R2CValScore_=None, RSS_=None, R2_=None, Out_=None):\n",
    "        \n",
    "        self.model_ = model_\n",
    "        self.RSSent_ = RSSent_\n",
    "        self.RSSeva_ = RSSeva_\n",
    "        self.R2ent_ = R2ent_\n",
    "        self.R2eva_ = R2eva_\n",
    "        self.Betas_ = Betas_\n",
    "        self.R2CValScore_ = R2CValScore_\n",
    "        self.RSS_ = RSS_\n",
    "        self.R2_ = R2_\n",
    "        self.Out_ = Out_\n",
    "        \n",
    "    #endfunction\n",
    "    \n",
    "#endclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ffabc3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# El objetivo de esta clase es añadirle atributos adicionales a los arreglos numpy de relevancia para el estudio\n",
    "# como lo son las variables estadísticas de interés.\n",
    "\n",
    "class StatsArr(np.ndarray):\n",
    "    \n",
    "    def __new__(cls, input_array, mean_=None, median_=None, mode_=None, max_=None, min_=None, range_=None, desv_=None, \n",
    "                skew_=None, kurt_=None, dataCorr_=None, Q1_=None, Q2_=None, Q3_=None, IQR_=None, TransfType_=None, \n",
    "                Lambdas_=None):\n",
    "        # Input array is an already formed ndarray instance\n",
    "        # We first cast to be our class type\n",
    "        obj = np.asarray(input_array).view(cls)\n",
    "        # add the new attribute to the created instance\n",
    "        obj.mean_ = mean_\n",
    "        obj.median_ = median_\n",
    "        obj.mode_ = mode_\n",
    "        obj.max_ = max_\n",
    "        obj.min_ = min_\n",
    "        obj.range_ = range_\n",
    "        obj.desv_ = desv_\n",
    "        obj.skew_ = skew_\n",
    "        obj.kurt_ = kurt_\n",
    "        obj.dataCorr_ = dataCorr_\n",
    "        obj.Q1_ = Q1_\n",
    "        obj.Q2_ = Q2_\n",
    "        obj.Q3_ = Q3_\n",
    "        obj.IQR_ = IQR_\n",
    "        obj.Transftype_ = TransfType_\n",
    "        obj.Lambdas_ = Lambdas_\n",
    "        # Finally, we must return the newly created object:\n",
    "        return obj\n",
    "    \n",
    "    #endfunction\n",
    "\n",
    "    def __array_finalize__(self, obj):\n",
    "        # see InfoArray.__array_finalize__ for comments\n",
    "        if obj is None: return\n",
    "        self.mean_   = getattr(obj, 'mean_', None)\n",
    "        self.median_ = getattr(obj, 'median_', None)\n",
    "        self.mode_   = getattr(obj, 'mode_', None)\n",
    "        self.max_    = getattr(obj, 'max_', None)\n",
    "        self.min_    = getattr(obj, 'min_', None)\n",
    "        self.range_  = getattr(obj, 'range_', None)\n",
    "        self.desv_   = getattr(obj, 'desv_', None)\n",
    "        self.skew_   = getattr(obj, 'skew_', None)\n",
    "        self.kurt_   = getattr(obj, 'kurt_', None)\n",
    "        self.dataCorr_ = getattr(obj, 'dataCorr_', None)\n",
    "        self.Q1_ = getattr(obj, 'Q1_', None)\n",
    "        self.Q2_ = getattr(obj, 'Q2_', None)\n",
    "        self.Q3_ = getattr(obj, 'Q3_', None)\n",
    "        self.IQR_ = getattr(obj, 'IQR_', None)\n",
    "        self.TransfType_ = getattr(obj, 'TransfType_', None)\n",
    "        self.Lambdas_ = getattr(obj, 'Lambdas_', None)\n",
    "        # We do not need to return anything\n",
    "    \n",
    "    #endfunction\n",
    "    \n",
    "#endclass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae94218f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a5b58fdb",
   "metadata": {},
   "source": [
    "\\newpage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97c7b80",
   "metadata": {},
   "source": [
    "\\vspace{1cm} \\section{\\scshape\\large Información relevante de la base de datos}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f0ef11",
   "metadata": {},
   "source": [
    "La data se encuentra estructurada por un conjunto de muestra de 10 sujetos, quienes fueron sometidos a 5 actividades de las siguientes: caminar, caminar hacia atrás, correr, caminar en plano inclinado, caminar en escaleras o en bicicleta estática. Cada sujeto posee estas actividades posee 5 grupos de señales clasificadas de acuerdo a su naturaleza y ubicación en el individuo de prueba. Por último, cada una de las señales de dicha clasificación posee 3 atributos: data, frecuencia de muestreo y nombres (ver Figura 1)\n",
    "\n",
    "\\begin{center}\n",
    "    \\includegraphics[width=0.6\\textwidth]{dataStruct.png} \\\\\n",
    "    Figura 1: Estructura de la data $[2]$\n",
    "\\end{center}\n",
    "\n",
    "\n",
    "\n",
    "Para cada uno de estos procesos se recolectó data de diferentes músculos en forma de señales EMG y en señales de aceleración, velocidad angular y campo magnético de acelerómetros de 3 ejes, en su mayoría ubicado en las piernas. también se midió la temperatura y actividad electrodermica de los individuos, así como otras señales metabólicas, como consumo de oxígeno, producción de dióxido de carbono, nivel de saturación de respiración, entre otros. Todas las señales se presentan en las Figuras 2 y 3.\n",
    "\n",
    "\\begin{center}\n",
    "    \\includegraphics[width=0.6\\textwidth]{dataSensor1.png} \\\\\n",
    "    Figura 2: Señales presentes en cada grupo - parte 1 $[2]$\n",
    "\\end{center}\n",
    "\n",
    "Entre los puntos importantes a mencionar de la data está el hecho de que, si bien cada clasificación de señales posee su propia tasa de muestreo, cada una posee 2 señales adicionales: una que indica el paso temporal del registro de la señal y otra que simplemente indica la actividad que se realiza con un código. esta segunda señal adicional es despreciable y se descarta al momento de realizar el procesado de las señales. Por otro lado, la señal temporal en cada clasificación no comienza ni termina en el mismo instante de tiempo, lo que necesariamente obliga a usar la interpolación como método de re muestreo para asegurar que todas las señales procesadas mantengan un mismo vector de tiempo de igual espaciado.\n",
    "\n",
    "\n",
    "\\begin{center}\n",
    "    \\includegraphics[width=0.6\\textwidth]{dataSensor2.png} \\\\\n",
    "    Figura 3: Señales presentes en cada grupo - parte 2 $[2]$\n",
    "\\end{center}\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2414de8a",
   "metadata": {},
   "source": [
    "\\vspace{1cm} \\section{\\scshape\\large Procesamiento de la data}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68020c84",
   "metadata": {},
   "source": [
    "Para el procesamiento de las señales, se realizó un proceso similar a aplicado en la referencia [1]: básicamente el conjunto de señales EMG fue filtrado con un filtro pasa altos con frecuencia de corte de 30 y un filtro pasa bajos con frecuencia de corte de 350. El resto de las señales no fue sometida a ningún tipo de filtrado de este tipo. \n",
    "\n",
    "Posteriormente se aplicó un filtro que suavizara la señal ante los efectos de ruido. En el caso de este trabajo, se implementó el filtro Savitzky-Golay con características adaptadas a cada señal de la siguiente manera:\n",
    "\n",
    "\\begin{itemize}\n",
    "    \\item[$\\bullet$] Señales APDL Accel: Se aplicó un filtro de orden 3 con una ventana de 10 segundo.\n",
    "    \\item[$\\bullet$] Señales EMG: Se aplicó un filtro de orden 3 con una ventana de 1 segundo.\n",
    "    \\item[$\\bullet$] Señales Epatical Accel: Se aplicó un filtro de orden 3 con una ventana de 10 segundo.\n",
    "    \\item[$\\bullet$] Señales Epatical Psysio: Se aplicó un filtro de orden 3 con una ventana de 10 segundo.\n",
    "    \\item[$\\bullet$] Señales Metabolics System: Se aplicó un filtro de orden 3 con una ventana de 1 segundo para todas las señales exceptuando la señal de nivel de saturación de oxígeno.\n",
    "\\end{itemize}\n",
    "\n",
    "En [1] usan un filtro lineal gaussiano, pero, por factores de costo computacional, y para realizar otra prueba con otro tipo de filtro, se seleccionó el filtro Savitzky-Golay.\n",
    "\n",
    "Posteriormente, debido a que las señales poseen diferentes tasas de muestreo e inician y finalizan en instantes de tiempo diferentes, se aplicó una interpolación linal a una frecuencia de muestreo específica, usando el instante de tiempo inicial mayor de todas las señales como instante de inicio y el instante final menor de todas las señales como punto final de la señal. Esto implica que, además de remuestrear las señales, también se truncó parte de la información al momento de realizar el remuestreo. Esto se hizo con la finalidad de evitar la extrapolación (creación de datos que necesariamente introducen error) para un rango de tiempo menor a 5 segundo de señales que duran más de 10 minutos. \n",
    "\n",
    "Todas las señales fueron remuestreadas a 500 Hz para este caso, se escogió 500 Hz como la tasa de muestreo para evitar perder información valiosa de las señales EMG, pero manteniendo un tamaño de data que, si bien sigue siendo grande, es manejable dentro de las capacidades computacionales disponibles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "48187ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lectura de la data\n",
    "data = np.empty( np.size(filename,0), dtype=object)\n",
    "for i in range(np.size(filename,0)): data[i] = h5py.File( filename[i], 'r+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0c6f6352",
   "metadata": {},
   "outputs": [],
   "source": [
    "#instanciación de los filtros para la señal EMG\n",
    "IirHP30, IirLP350 = filtros(data, 0, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "af67d3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtrado de toda la data\n",
    "procAllSubActvData( data, \"procsData1\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8c9f3464",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remuestreado de la data\n",
    "AllSunjActvReSampData( data, \"procsData1\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bce6f445",
   "metadata": {},
   "outputs": [],
   "source": [
    "#callData1( data, 1, 0, 0 ).keys()\n",
    "#del callData2( data, 0, 0)[\"procsData1\"]\n",
    "#del callData2( data, 0, 1)[\"procsData1\"]\n",
    "#callData2( data, 0, 0)[\"procsData1\"] = 0\n",
    "#print( callData2( data, 0, 0 ).keys() )\n",
    "#print( callData2( data, 0, 1 ).keys() )\n",
    "#print( callData2( data, 0, 2 ).values() )\n",
    "#callData1( data, 0, 1, 4)['Data']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518748d2",
   "metadata": {},
   "source": [
    "\\vspace{1cm} \\section{\\scshape\\large Modelo Implementado}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522307d8",
   "metadata": {},
   "source": [
    "En esta experiencia, como primera iteración, se decidió implementar un modelo de regresión lineal basado en la metodología de [1], quienes implementaron ese tipo de modelo para estimar los valores de consumo energético.\n",
    "\n",
    "En esta ocasión, solo se aplicará para cada individuo por separado a fin de mostrar la convergencia del método, con el fin de tener un primer resultado que certifique la validez del mismo.\n",
    "\n",
    "Para comparar los resultados, en vista de tener directamente de los datos el consumo de oxígeno y producción de dióxido de carbono, pero no tener de forma explícita el valor del nitrógeno excretado, siguiendo los modelos que no dependen de este valor faltante según la Figura 4, la curva \"teórica\" de consumo de energía se obtuvo del promediar el modelo Garby and Astrup 1987 y el modelo de Péronnet and Massicotte 1991.\n",
    "\n",
    "\\begin{center}\n",
    "    \\includegraphics[width=0.6\\textwidth]{TablaEcuacionesCalorimetras.png} \\\\\n",
    "    Figura 4: Tabla de ecuaciones calorímetras $[2]$\n",
    "\\end{center}\n",
    "\n",
    "Dichos valores fueron calculados al momento de remuestrear la data, aprovechando que se construye una nueva matriz con todas las señales de interés respecto al vector de tiempo correspondiente de referencia.\n",
    "\n",
    "Una vez se tienen todas las señales remuestradas a la misma tasa de muestreo y se ha calculado la referencia, se procede a implementar el modelo. En este caso, al no realizar ningún tipo de clasificación, solamente se dispone de valores de error como el ERMS para validar el resultado obtenido. En esta primera experiencia, se escoge aplicar un modelo de validación cruzada de 5 iteraciones y otro de 10 iteraciones para comparar resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d8c8ffb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Instancias de las variables de interés para el modelo de regresión lineal con validación cruzada de 5 iteraciones\n",
    "mR2ent5K = np.zeros( (np.size(subjname,0), np.size(actvname,0)) )\n",
    "mR2eva5K = np.zeros( (np.size(subjname,0), np.size(actvname,0)) )\n",
    "mR2all5K = np.zeros( (np.size(subjname,0), np.size(actvname,0)) )\n",
    "LRmodel5K = np.empty( (np.size(subjname,0), np.size(actvname,0)), dtype = object )\n",
    "\n",
    "\n",
    "# Instancias de las variables de interés para el modelo de regresión lineal con validación cruzada de 5 iteraciones\n",
    "mR2ent10K = np.zeros( (np.size(subjname,0), np.size(actvname,0)) )\n",
    "mR2eva10K = np.zeros( (np.size(subjname,0), np.size(actvname,0)) )\n",
    "mR2all10K = np.zeros( (np.size(subjname,0), np.size(actvname,0)) )\n",
    "LRmodel10K = np.empty( (np.size(subjname,0), np.size(actvname,0)), dtype = object )\n",
    "      \n",
    "    \n",
    "# ejecución del modelo para todas las actividades de todos los sujetos de pruebas\n",
    "for j in range( np.size( subjname,0 ) ):\n",
    "    \n",
    "    for i in range( np.size( actvname,0 ) ):\n",
    "        \n",
    "        #regresión lineal con validación cruzada de 5 iteraciones\n",
    "        LRmodel5K[j,i] = ModelsInfo()\n",
    "        LRmodel5K[j,i].RSSent_ , LRmodel5K[j,i].RSSeva_ , LRmodel5K[j,i].R2ent_ , LRmodel5K[j,i].R2eva_ , LRmodel5K[j,i].model_ = LinearRegrDSplit( data = callData2(data, j, i)[\"procsData1\"][1:,:].transpose(), trdSplit = 5 )\n",
    "        mR2ent5K[j,i] = LRmodel5K[j,i].R2ent_\n",
    "        mR2eva5K[j,i] = LRmodel5K[j,i].R2eva_\n",
    "        mR2all5K[j,i] = LRmodel5K[j,i].model_.score(callData2(data, j, i)[\"procsData1\"][2:,:].transpose(), callData2(data, j, i)[\"procsData1\"][1,:].transpose())\n",
    "        \n",
    "        \n",
    "        #regresión lineal con validación cruzada de 10 iteraciones\n",
    "        LRmodel10K[j,i] = ModelsInfo()\n",
    "        LRmodel10K[j,i].RSSent_ , LRmodel10K[j,i].RSSeva_ , LRmodel10K[j,i].R2ent_ , LRmodel10K[j,i].R2eva_ , LRmodel10K[j,i].model_ = LinearRegrDSplit( data = callData2(data, j, i)[\"procsData1\"][1:,:].transpose(), trdSplit = 10 )\n",
    "        mR2ent10K[j,i] = LRmodel10K[j,i].R2ent_\n",
    "        mR2eva10K[j,i] = LRmodel10K[j,i].R2eva_\n",
    "        mR2all10K[j,i] = LRmodel10K[j,i].model_.score(callData2(data, j, i)[\"procsData1\"][2:,:].transpose(), callData2(data, j, i)[\"procsData1\"][1,:].transpose())\n",
    "    \n",
    "    #endfor\n",
    "    \n",
    "#endfor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5908f19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "820d2aee",
   "metadata": {},
   "source": [
    "\\newpage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af9ccc3",
   "metadata": {},
   "source": [
    "\\vspace{1cm} \\section{\\scshape\\large Resultados}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc8c7c9",
   "metadata": {},
   "source": [
    "A continuación, se presentan los resultados obtenidos del modelo de regresión lineal con validación cruzada de 5 y 10 iteraciones en tablas específicas donde se muestra el valor correspondiente de cada sujeto en cada actividad realizada y su correspondiente media y desviación estándar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "d9d3e1f3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regresión Lineal. ERMS para 5k entrenamiento\n",
      "+-----------+-----------+---------+---------+---------+---------+------+-----+\n",
      "|  subjects | Backwards | Cycling | Incline | Running | Walking | mean |  SD |\n",
      "+-----------+-----------+---------+---------+---------+---------+------+-----+\n",
      "| Subject01 |    1.0    |   1.0   |   1.0   |   1.0   |   1.0   | 1.0  | 0.0 |\n",
      "| Subject02 |    1.0    |   1.0   |   1.0   |   1.0   |   1.0   | 1.0  | 0.0 |\n",
      "| Subject03 |    1.0    |   1.0   |   1.0   |   1.0   |   1.0   | 1.0  | 0.0 |\n",
      "| Subject04 |    1.0    |   1.0   |   1.0   |   1.0   |   1.0   | 1.0  | 0.0 |\n",
      "| Subject05 |    1.0    |   1.0   |   1.0   |   1.0   |   1.0   | 1.0  | 0.0 |\n",
      "| Subject06 |    1.0    |   1.0   |   1.0   |   1.0   |   1.0   | 1.0  | 0.0 |\n",
      "| Subject07 |    1.0    |   1.0   |   1.0   |   1.0   |   1.0   | 1.0  | 0.0 |\n",
      "| Subject08 |    1.0    |   1.0   |   1.0   |   1.0   |   1.0   | 1.0  | 0.0 |\n",
      "| Subject09 |    1.0    |   1.0   |   1.0   |   1.0   |   1.0   | 1.0  | 0.0 |\n",
      "| Subject10 |    1.0    |   1.0   |   1.0   |   1.0   |   1.0   | 1.0  | 0.0 |\n",
      "|   media   |    1.0    |   1.0   |   1.0   |   1.0   |   1.0   |  --  |  -- |\n",
      "|    STD    |    0.0    |   0.0   |   0.0   |   0.0   |   0.0   |  --  |  -- |\n",
      "+-----------+-----------+---------+---------+---------+---------+------+-----+\n",
      "\n",
      "Regresión Lineal. ERMS para 5k evaluación\n",
      "+-----------+-----------+---------+---------+---------+---------+-------+-------+\n",
      "|  subjects | Backwards | Cycling | Incline | Running | Walking |  mean |   SD  |\n",
      "+-----------+-----------+---------+---------+---------+---------+-------+-------+\n",
      "| Subject01 |   0.975   |  0.881  |  0.987  |  0.991  |  0.952  | 0.957 |  0.04 |\n",
      "| Subject02 |   0.988   |  0.932  |  0.901  |  0.924  |  0.861  | 0.921 | 0.042 |\n",
      "| Subject03 |   0.936   |  0.976  |  0.989  |  0.988  |  0.734  | 0.925 | 0.097 |\n",
      "| Subject04 |    0.95   |  0.019  |  0.988  |  0.958  |   0.97  | 0.777 | 0.379 |\n",
      "| Subject05 |    0.98   |  0.021  |  0.884  |  0.931  |  0.298  | 0.622 | 0.389 |\n",
      "| Subject06 |   0.942   |  0.989  |  0.938  |  0.974  |  0.898  | 0.948 | 0.032 |\n",
      "| Subject07 |    0.58   |  0.346  |  0.904  |  0.974  |  0.697  |  0.7  | 0.227 |\n",
      "| Subject08 |   -0.696  |  0.929  |  0.935  |  0.994  |  0.896  | 0.612 | 0.654 |\n",
      "| Subject09 |   0.406   |  0.664  |  0.944  |  0.978  |  0.411  | 0.681 | 0.248 |\n",
      "| Subject10 |   0.969   |  0.974  |  0.958  |  0.991  |   0.67  | 0.912 | 0.122 |\n",
      "|   media   |   0.703   |  0.673  |  0.943  |   0.97  |  0.739  |   --  |   --  |\n",
      "|    STD    |   0.503   |  0.377  |  0.036  |  0.024  |  0.217  |   --  |   --  |\n",
      "+-----------+-----------+---------+---------+---------+---------+-------+-------+\n",
      "\n",
      "Regresión Lineal. ERMS para 5k toda la data\n",
      "+-----------+-----------+---------+---------+---------+---------+-------+-------+\n",
      "|  subjects | Backwards | Cycling | Incline | Running | Walking |  mean |   SD  |\n",
      "+-----------+-----------+---------+---------+---------+---------+-------+-------+\n",
      "| Subject01 |   0.975   |  0.881  |  0.987  |  0.991  |  0.952  | 0.957 |  0.04 |\n",
      "| Subject02 |   0.988   |  0.932  |  0.901  |  0.924  |  0.861  | 0.921 | 0.042 |\n",
      "| Subject03 |   0.936   |  0.976  |  0.989  |  0.988  |  0.734  | 0.925 | 0.097 |\n",
      "| Subject04 |    0.95   |  0.019  |  0.988  |  0.958  |   0.97  | 0.777 | 0.379 |\n",
      "| Subject05 |    0.98   |  0.021  |  0.884  |  0.931  |  0.298  | 0.622 | 0.389 |\n",
      "| Subject06 |   0.942   |  0.989  |  0.938  |  0.974  |  0.898  | 0.948 | 0.032 |\n",
      "| Subject07 |    0.58   |  0.346  |  0.904  |  0.974  |  0.697  |  0.7  | 0.227 |\n",
      "| Subject08 |   -0.696  |  0.929  |  0.935  |  0.994  |  0.896  | 0.612 | 0.654 |\n",
      "| Subject09 |   0.406   |  0.664  |  0.944  |  0.978  |  0.411  | 0.681 | 0.248 |\n",
      "| Subject10 |   0.969   |  0.974  |  0.958  |  0.991  |   0.67  | 0.912 | 0.122 |\n",
      "|   media   |   0.703   |  0.673  |  0.943  |   0.97  |  0.739  |   --  |   --  |\n",
      "|    STD    |   0.503   |  0.377  |  0.036  |  0.024  |  0.217  |   --  |   --  |\n",
      "+-----------+-----------+---------+---------+---------+---------+-------+-------+\n",
      "\n",
      "Regresión Lineal. ERMS para 10k entrenamiento\n",
      "+-----------+-----------+---------+---------+---------+---------+------+-----+\n",
      "|  subjects | Backwards | Cycling | Incline | Running | Walking | mean |  SD |\n",
      "+-----------+-----------+---------+---------+---------+---------+------+-----+\n",
      "| Subject01 |    1.0    |   1.0   |   1.0   |   1.0   |   1.0   | 1.0  | 0.0 |\n",
      "| Subject02 |    1.0    |   1.0   |   1.0   |   1.0   |   1.0   | 1.0  | 0.0 |\n",
      "| Subject03 |    1.0    |   1.0   |   1.0   |   1.0   |   1.0   | 1.0  | 0.0 |\n",
      "| Subject04 |    1.0    |   1.0   |   1.0   |   1.0   |   1.0   | 1.0  | 0.0 |\n",
      "| Subject05 |    1.0    |   1.0   |   1.0   |   1.0   |   1.0   | 1.0  | 0.0 |\n",
      "| Subject06 |    1.0    |   1.0   |   1.0   |   1.0   |   1.0   | 1.0  | 0.0 |\n",
      "| Subject07 |    1.0    |   1.0   |   1.0   |   1.0   |   1.0   | 1.0  | 0.0 |\n",
      "| Subject08 |    1.0    |   1.0   |   1.0   |   1.0   |   1.0   | 1.0  | 0.0 |\n",
      "| Subject09 |    1.0    |   1.0   |   1.0   |   1.0   |   1.0   | 1.0  | 0.0 |\n",
      "| Subject10 |    1.0    |   1.0   |   1.0   |   1.0   |   1.0   | 1.0  | 0.0 |\n",
      "|   media   |    1.0    |   1.0   |   1.0   |   1.0   |   1.0   |  --  |  -- |\n",
      "|    STD    |    0.0    |   0.0   |   0.0   |   0.0   |   0.0   |  --  |  -- |\n",
      "+-----------+-----------+---------+---------+---------+---------+------+-----+\n",
      "\n",
      "Regresión Lineal. ERMS para 10k evaluación\n",
      "+-----------+-----------+---------+---------+---------+---------+-------+-------+\n",
      "|  subjects | Backwards | Cycling | Incline | Running | Walking |  mean |   SD  |\n",
      "+-----------+-----------+---------+---------+---------+---------+-------+-------+\n",
      "| Subject01 |    0.99   |  0.993  |  0.992  |  0.998  |  0.995  | 0.994 | 0.003 |\n",
      "| Subject02 |   0.993   |  0.998  |  0.996  |  0.974  |  0.925  | 0.977 | 0.027 |\n",
      "| Subject03 |   0.985   |  0.989  |  0.996  |  0.985  |  0.988  | 0.989 | 0.004 |\n",
      "| Subject04 |   0.955   |  0.925  |  0.992  |  0.997  |  0.991  | 0.972 | 0.028 |\n",
      "| Subject05 |   0.996   |   0.99  |  0.994  |  0.999  |  0.993  | 0.994 | 0.003 |\n",
      "| Subject06 |   0.972   |  0.991  |  0.974  |  0.891  |  0.976  | 0.961 | 0.036 |\n",
      "| Subject07 |   0.976   |  0.957  |  0.982  |  0.914  |  0.978  | 0.961 | 0.025 |\n",
      "| Subject08 |   0.947   |  0.991  |  0.989  |  0.997  |  0.977  |  0.98 | 0.018 |\n",
      "| Subject09 |   0.987   |  0.933  |  0.984  |  0.996  |  0.991  | 0.978 | 0.023 |\n",
      "| Subject10 |   0.954   |   0.98  |  0.992  |  0.983  |  0.929  | 0.968 | 0.023 |\n",
      "|   media   |   0.976   |  0.975  |  0.989  |  0.973  |  0.974  |   --  |   --  |\n",
      "|    STD    |   0.017   |  0.025  |  0.007  |  0.037  |  0.024  |   --  |   --  |\n",
      "+-----------+-----------+---------+---------+---------+---------+-------+-------+\n",
      "\n",
      "Regresión Lineal. ERMS para 10k toda la data\n",
      "+-----------+-----------+---------+---------+---------+---------+-------+-------+\n",
      "|  subjects | Backwards | Cycling | Incline | Running | Walking |  mean |   SD  |\n",
      "+-----------+-----------+---------+---------+---------+---------+-------+-------+\n",
      "| Subject01 |    0.99   |  0.993  |  0.992  |  0.998  |  0.995  | 0.994 | 0.003 |\n",
      "| Subject02 |   0.993   |  0.998  |  0.996  |  0.974  |  0.925  | 0.977 | 0.027 |\n",
      "| Subject03 |   0.985   |  0.989  |  0.996  |  0.985  |  0.988  | 0.989 | 0.004 |\n",
      "| Subject04 |   0.955   |  0.925  |  0.992  |  0.997  |  0.991  | 0.972 | 0.028 |\n",
      "| Subject05 |   0.996   |   0.99  |  0.994  |  0.999  |  0.993  | 0.994 | 0.003 |\n",
      "| Subject06 |   0.972   |  0.991  |  0.974  |  0.891  |  0.976  | 0.961 | 0.036 |\n",
      "| Subject07 |   0.976   |  0.957  |  0.982  |  0.914  |  0.978  | 0.961 | 0.025 |\n",
      "| Subject08 |   0.947   |  0.991  |  0.989  |  0.997  |  0.977  |  0.98 | 0.018 |\n",
      "| Subject09 |   0.987   |  0.933  |  0.984  |  0.996  |  0.991  | 0.978 | 0.023 |\n",
      "| Subject10 |   0.954   |   0.98  |  0.992  |  0.983  |  0.929  | 0.968 | 0.023 |\n",
      "|   media   |   0.976   |  0.975  |  0.989  |  0.973  |  0.974  |   --  |   --  |\n",
      "|    STD    |   0.017   |  0.025  |  0.007  |  0.037  |  0.024  |   --  |   --  |\n",
      "+-----------+-----------+---------+---------+---------+---------+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ResultTables = LRallTables( allResults )\n",
    "printResults( ResultTables, 'Regresión Lineal. ERMS para ', methodName )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef507cc",
   "metadata": {},
   "source": [
    "Es impoEs importante mencionar que los valores del error cuadrático medio fueron directamente calculados de la función score ofrecida como método del modelo una vez instanciado y entrenado.\n",
    "\n",
    "De acá se puede apreciar que la regresión lineal con validación cruzada de 10 iteraciones refleja una mejora sustancial sobre el mismo método con 5 iteraciones. En ambos casos, ambos obtienen puntajes perfectos al momento de ser entrenados, lo que puede deberse a la gran cantidad de datos que posee cada muestra de cada actividad y a que la señal se comporta como una señal continua, lo que pudiera facilitar la predicción.\n",
    "\n",
    "Sin embargo, al ejecutar el modelo entrenado contra los datos de evaluación, claramente el modelo con solo 5 iteraciones tiene problemas para predecir varios valores, resultando en baja precisión en los valores en diferentes actividades de un individuo (que se refleja en la media), causando grandes desviaciones en los resultados. Los resultados no mejoran si se evalúa la media y desviación estándar por sujeto en vez de actividad, ya que existen casos para algunos individuos en todas las actividades donde el modelo no presenta un desempeño apropiado. La discrepancia entre los resultados puede deberse a la gran cantidad de datos que hace insuficiente realizar una validación cruzada de 5 iteraciones, pues el modelo no logra predecir apropiadamente el comportamiento en varios casos (casos que en conjunto incluyen al menos dos casos para cada actividad, causando la disminución del desempeño total tanto en individuos para una actividad como en actividades de un individuo). Cabe destacar que todos son modelos independientes únicamente entrenados con la data de una actividad asociada a un individuo.\n",
    "\n",
    "Por otro lado, el modelo con validación cruzada de 10 iteraciones muestra ser lo suficientemente preciso y robusto en todos los casos, manteniendo medias por encima del 96.5% para las actividades asociadas a un individuo y para los resultados de todos los individuos en una actividad, proporcionando una desviación estándar del orden de ${10}^{-2}$, lo que muestra la constancia de esta configuración, por lo que es el conjunto de modelos resultantes apropiados para este problema.\n",
    " la constancia de esta configuración, por lo que es el conjunto de modelos resultantes apropiados para este problema."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94b336a",
   "metadata": {},
   "source": [
    "Resulta importante destacar que, para las pruebas realizadas, los algoritmos ejecutados tardaron alrededor de 35min en \n",
    "solo realizar el filtrado y el remuestreo, lo que señala lo relevante del tamaño de la data al operarla. Adicionalmente, al operar la data y almacenar los valores procesados, el consumo de almacenamiento se incrementó considerablemente, pasando de 8GB a más de 40GB. Esto ocurre porque el filtrado no reduce el tamaño de la data (salvo por la eliminación de señales NaN), lo que se considera como casi duplicar la data; mientras que el remuestrear las señales a 500Hz converge a un aumento sustancial del tamaño de la data para todas las señales, excepto la EMG, que reduce su tamaño a la mitad. Como exiten señales muestreadas a 128Hz, 32Hz y menos de 1Hz, este remuestreo equivale a multiplicar exponencialmente la data, por lo que solo este proceso contribuye consumir más de 30GB de almacenamiento.\n",
    "\n",
    "Estos factores de requisitos computacionales resultan esenciales para futuras pruebas, a modo de obtener una planificación que permita el uso eficiente de los recursos computacionales presentes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da63e8b",
   "metadata": {},
   "source": [
    "\\newpage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3291a842",
   "metadata": {},
   "source": [
    "\\vspace{1cm} \\section{\\scshape\\large Conclusiones}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ccd2723",
   "metadata": {},
   "source": [
    "Del presente trabajo, se pudo demostrar la validez de la aplicación del modelo de regresión lineal, modelo implementado [1]. Sin embargo, cualquier configuración no es lo suficientemente buena como para ser apropiada. Para el presente caso, al trabajar con más de 60 señales de longitudes superiores a las 880000 muestras, resulta muy complicado para los modelos con validación cruzada con bajas cantidades de iteraciones conseguir buenos resultados en alguno de los casos.\n",
    "\n",
    "Adicionalmente, se pudo tener una compresión del significado de la data y lo que se requiere para trabajar con una data de 8GB. Las limitaciones computacionales, si bien no fueron relevantes en este proceso, salvo por requerimientos de tiempo, el realizar procesamiento de la data de diferentes formas para su posterior almacenamiento conlleva a requerir grandes cantidades de espacio de almacenamiento para poder ser trabajada, lo que puede ser un elemento a tomar en cuenta al realizar diferentes pruebas. Para este proyecto, se consumieron más de 40GB y sólo se realizó un filtrado, suavizado y remuestreo de las señales.\n",
    "\n",
    "El proyecto se concluye con un resultado satisfactorio, ya sea solo para los valores de un individuo, por alcanzar una precisión superior al 96% en todos los casos para el modelo de regresión lineal con validación cruzada de 10 iteraciones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d723748",
   "metadata": {},
   "source": [
    "\\newpage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9008a3a",
   "metadata": {},
   "source": [
    "\\vspace{1cm} \\section{\\scshape\\large Siguientes pasos}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d831e1af",
   "metadata": {},
   "source": [
    "\\begin{itemize}\n",
    "    \\item[$\\bullet$] De esta primera iteración, se valida la viabilidad del modelo de regresión lineal. No obstante, resulta indispensable realizar pruebas con diferentes modelos que permitan corroborar comportamientos\n",
    "    \\item[$\\bullet$] puede ser necesario aplicar modelos no supervisados en búsqueda de patrones que permitan tener una mayor compresión de la influencia que refleja cada señal respecto al consumo de energía de la persona y, posiblemente, desarrollar un modelo matemático asociado a las mismas.\n",
    "    \\item[$\\bullet$] Es prudente dar respuesta a las siguientes preguntas:\n",
    "    \\begin{itemize}\n",
    "        \\item[$\\bullet$] ¿qué modelos de estimación de costo energético son más precisos?\n",
    "        \\item[$\\bullet$] ¿qué elementos pueden ser estandarizar para el modelo?\n",
    "        \\item[$\\bullet$] ¿existen patrones de señales que permitan tener mejores resultados?\n",
    "        \\item[$\\bullet$] ¿combinar señales (EMG, Aceleración, velocidad y campo magnético del acelerómetro) como una señal de magnitud resultante podrían ofrecer una mejor ventaja?\n",
    "        \\item[$\\bullet$] ¿cómo parametrizar las variables para generar modelos que pudieran usar las 10 muestras?\n",
    "        \\item[$\\bullet$] No se tienen datos esenciales de cada paciente en específico: peso, edad, altura y sexo. ¿cuánto afecta en el proceso la carencia de los datos?\n",
    "    \\end{itemize}\n",
    "    \\item[$\\bullet$] Planificar las diferentes pruebas y procesamientos para diferentes modelos puede ser crucial para maximizar el aprovechamiento de los recursos computacionales. Es importante encontrar una forma de poder realizar todas las pruebas necesarias sin requerir capacidad de cómputo extra para las primeras etapas.\n",
    "\\end{itemize}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e36801b",
   "metadata": {},
   "source": [
    "\\newpage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef734fdc",
   "metadata": {},
   "source": [
    "\\vspace{1cm} \\section{\\scshape\\large Referencias Bibliográficas}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf62c11",
   "metadata": {},
   "source": [
    "[1]\t    Ingraham, Kimberly A.; Ferris, Daniel P.; Remy, C. David (2019). Evaluating physiological signal salience for estimating metabolic energy cost from wearable sensors. Link: \\href{https://figshare.com/articles/dataset/Predicting_energy_cost_from_wearable_sensors_A_dataset_of_energetic_and_physiological_wearable_sensor_data_from_healthy_individuals_performing_multiple_physical_activities/7473191/2}{figshare dataset}\n",
    "\n",
    "[2]\t    Ingraham, Kimberly A.; Ferris, Daniel P.; Remy, C. David (2019). Predicting energy cost from wearable sensors: A dataset of energetic and physiological wearable sensor data from healthy individuals performing multiple physical activities. Journal of Applied Physiology, 126(3), 717–729. doi:10.1152/japplphysiol.00714.2018\n",
    "\n",
    "[3]\t    Kipp, Shalaya & Byrnes, William & Kram, Rodger. (2018). Calculating metabolic energy expenditure across a wide range of exercise intensities: The equation matters. Applied Physiology, Nutrition, and Metabolism. 43. 10.1139/apnm-2017-0781.\n",
    "\n",
    "[4]\t    Westenskow, D. R.; Schipke, C. A.; Raymond, J. L.; Saffle, J. R.; Becker, J. M.; Young, E. W.; Cutler, C. A. (1988). Calculation of Metabolic Expenditure and Substrate Utilization from Gas Exchange Measurements. Journal of Parenteral and Enteral Nutrition, 12(1), 20–24. doi:10.1177/014860718801200120"
   ]
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "William Chacón"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "title": "Proyecto: Predicción del consumo energético metabólico humano"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
